<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Lingbo  Shen | Davidson and MacKinnon Chapter 4&mdash;Hypothesis Testing in Linear Regression Model</title>
    <meta name="author" content="Lingbo  Shen" />
    <meta name="description" content="The fourth chapter of Econometric Theory and Methods" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />

    <meta name="google-site-verification" content="45VVBTzbWI9CPrT2UtIdTtL6imAnvMgtV1VttR2zNGI" />
    
    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://lingboshen.github.io/blog/2022/DMCh4/">

    <!-- Dark Mode -->
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://lingboshen.github.io/"><span class="font-weight-bold">Lingbo</span>   Shen</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">Home</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Research</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">Teaching</a>
              </li>
<!-- Chinese -->
              <li class="nav-item ">
                <a class="nav-link" href="/chinese/">Chinese/中文</a>
              </li>

              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Davidson and MacKinnon Chapter 4—Hypothesis Testing in Linear Regression Model</h1>
    <p class="post-meta">October 23, 2022</p>
    <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
        ·  
        <a href="/blog/tag/note">
          <i class="fas fa-hashtag fa-sm"></i> note</a>  
          <a href="/blog/tag/econometics">
          <i class="fas fa-hashtag fa-sm"></i> econometics</a>  
          

    </p>
  </header>

  <article class="post-content">
    <h1 id="some-common-distributions-and-relationships">Some Common Distributions and Relationships</h1>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/DMCh4-distribution-relation-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/DMCh4-distribution-relation-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/DMCh4-distribution-relation-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/DMCh4-distribution-relation.jpg" data-zoomable="">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    <b>Relationships between common distributions</b>
</div>

<h2 id="the-normal-distrbution">The Normal Distrbution</h2>

\[\begin{eqnarray*}
Z&amp;\sim&amp;N(0,1)\\
X=\mu+\sigma Z&amp;\sim&amp;N(\mu, \sigma)\\
f(x)&amp;=&amp;\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}
\end{eqnarray*}\]

<p>Any linear combination of independent normally distributed random
variables is normally distributed.</p>

<p>Consider Multivariable Normal Distribution</p>

\[\begin{eqnarray*}
X&amp;\sim&amp;N(\mu, \Omega)
\end{eqnarray*}\]

<p>If \(a\) is an \(m-\)vector of fixed coefficients, then
\(a^{T}X\), which is a linear combination of normal
distribution, follows</p>

\[\begin{eqnarray*}
a^{T}X&amp;\sim&amp;N(a^{T}\mu, a^{T}\Omega a)
\end{eqnarray*}\]

<p>If \(X\) is any multivariate normal vector with zero covariances, the
components of \(X\) are mutually independent.</p>

<p>This is a very special property of the multivariate normal distribution.
Usually zero covariance doesn’t mean independent.</p>

<h2 id="the-chi-squared-distrbution">The Chi-Squared Distrbution</h2>

<p>Suppose the random vector \(Z\) is such that its components
\(z_{1}, z_{2},\cdots, z_{m}\) are mutually independent standard normal
distribution random variables, i.e. \(Z\sim N(0, I)\). Then
the random variable \(y\)</p>

\[\begin{eqnarray}
\label{eqd1}
y&amp;\equiv&amp;||Z||^{2}=Z^{T}Z=\sum_{i=1}^{m}z_{i}^{2}
\end{eqnarray}\]

<p>follows the <strong>chi-squared distirbution</strong> with \(m\) <strong>degrees of
freedom</strong>. We write is as</p>

\[\begin{eqnarray*}
y&amp;\sim&amp;\chi^{2}(m)
\end{eqnarray*}\]

<p>The mean of chi-squared distribution is \(m\), and its variance is \(2m\).</p>

<p>If \(y_{1}\sim \chi^{2}(m_{1})\), \(y_{2}\sim \chi^{2}(m_{2})\), and \(y_{1}\)
and \(y_{2}\) are independent, then</p>

\[\begin{eqnarray*}
y&amp;=&amp;y_{1}+y_{2}=\sum_{i=1}^{m_{1}+m_{2}}z_{i}^{2}\sim \chi^{2}(m_{1}+m_{2})
\end{eqnarray*}\]

<p>::: proposition</p>
<ol>
  <li>If the \(m-\)vector \(X\) is distributed as
\(N(0,\Omega)\), then the quadratic form</li>
</ol>

\[\begin{eqnarray}
    	\label{eqd2}
    	X^{T}\Omega^{-1}X&amp;\sim&amp;\chi^{2}(m)
    \end{eqnarray}\]

<ol>
  <li>If \(P\) is a projection matrix with rank \(r\) and \(Z\) is an
\(n-\)vector that is distributed as \(N(0,I)\), then the
quadratic form</li>
</ol>

\[\begin{eqnarray}
    	\label{eqd3}
    	Z^{T}PZ&amp;\sim&amp;\chi^{2}(r)
    \end{eqnarray}\]

<p>:::</p>

<p>::: proof
<em>Proof.</em></p>

<ol>
  <li>
    <p>Let \(Z=A^{-1}X\), where \(AA^{T}=\Omega\)</p>

    <p>Since the vector \(X\) is multivariate normal with mean vector
\(0\), so is the vector \(A^{-1}X\). The covariance of
\(A^{-1}X\) is</p>
  </li>
</ol>

\[\begin{eqnarray*}
    E\left(A^{-1}XX^{T}(A^{T})^{-1}\right)&amp;=&amp;A^{-1}E\left(XX^{T}\right)(A^{T})^{-1}\\
    &amp;=&amp;A^{-1}\Omega(A^{T})^{-1}=A^{-1}AA^{T}(A^{T})^{-1}\\
    &amp;=&amp;I_{m}
    \end{eqnarray*}\]

<p>So \(Z=A^{-1}X\sim N(0, I)\)
    Considering the quadratic form \(X^{T}\Omega^{-1}X\),
    we have</p>

\[\begin{eqnarray*}
    X^{T}\Omega^{-1}X&amp;=&amp;X^{T}(AA^{T})^{-1}X\\
    &amp;=&amp;X^{T}(A^{T})^{-1}A^{-1}X\\
    &amp;=&amp;Z^{T}Z\sim \chi^{2}(m)
    \end{eqnarray*}\]

<ol>
  <li>Suppose \(P\) projects on to the span of the columns of an
\(n\times r\) matrix \(Z\). This allows us to write</li>
</ol>

\[\begin{eqnarray*}
    Z^{T}PZ&amp;=&amp;Z^{T}Z(Z^{T}Z)^{-1}Z^{T}Z
    \end{eqnarray*}\]

<p>Let \(X=Z^{T}Z\), and
    \(X\sim N(0,Z^{T}Z)\). Therefore,</p>

\[\begin{eqnarray*}
    Z^{T}PZ&amp;=&amp;X^{T}(Z^{T}Z)^{-1}X
    \end{eqnarray*}\]

<p>where \(Z^{T}Z\) is the variance of
    \(X\). Use the first part of the theorem, we prove that
    \(Z^{T}PZ\) is distributed as \(\chi^{2}(r)\).</p>

<p>◻
:::</p>

<h2 id="the-students-t-distribution">The Student’s t Distribution</h2>

<p>If \(z\sim N(0,1)\) and \(y\sim \chi^{2}(m)\), and \(z\) and \(y\) are
independent, then the random variable</p>

\[\begin{eqnarray}
\label{eqd4}
z&amp;\equiv&amp;\frac{z}{(y/m)^{1/2}}
\end{eqnarray}\]

<p>is said to follow the <strong>Student’s t disribution</strong> with
\(m\) degrees of freedom. We write is as</p>

\[\begin{eqnarray*}
t&amp;\sim&amp;t(m)
\end{eqnarray*}\]

<h2 id="the-f-distribution">The F Distribution</h2>

<p>If \(y_{1}\sim \chi^{2}(m_{1})\) and \(y_{2}\sim \chi^{2}(m_{2})\), and
\(y_{1}\) and \(y_{2}\) are independent, then the random variable</p>

\[\begin{eqnarray}
\label{eqd5}
F&amp;\equiv&amp;\frac{y_{1}/m_{1}}{y_{2}/m_{2}}
\end{eqnarray}\]

<p>is said to follow the <strong>F distribution</strong> with \(m_{1}\)
and \(m_{2}\) degrees of freedom. We write it as</p>

\[\begin{eqnarray}
F&amp;\sim&amp;F(m_{1}, m_{2})
\end{eqnarray}\]

<h1 id="tests-of-a-single-restriction">Tests of a Single Restriction</h1>

<p>We want to test \(\beta_{2}=0\)</p>

\[\begin{eqnarray}
\label{eq6}
y&amp;=&amp;X_{1}\beta_{1}+\beta_{2}x_{2}+u\\
\nonumber
M_{1}y&amp;=&amp;\beta_{2}M_{1}x_{2}+M_{1}u
\end{eqnarray}\]

<p>We find that</p>

\[\begin{eqnarray*}
\hat{\beta}_{2}&amp;=&amp;\frac{X_{2}^{T}M_{1}y}{X_{2}^{T}M_{1}X_{2}}\\
Var(\hat{\beta}_{2})&amp;=&amp;\sigma^{2}\left(X_{2}^{T}M_{1}X_{2}\right)^{-1}
\end{eqnarray*}\]

<p>For the null hypothesis that \(\beta_{2}=0\), this yields a test statistic</p>

\[\begin{eqnarray}
\label{eq7}
z_{\beta_{2}}&amp;=&amp;\frac{X_{2}^{T}M_{1}y}{\sigma\left(X_{2}^{T}M_{1}X_{2}\right)^{1/2}}\\
\label{eq8}
&amp;=&amp;\frac{X_{2}^{T}M_{1}u}{\sigma\left(X_{2}^{T}M_{1}X_{2}\right)^{1/2}}\sim N(0,1)
\end{eqnarray}\]

<p>However, we do not know \(\sigma\). We need to replace \(\sigma\) by \(s\)</p>

\[\begin{eqnarray*}
s^{2}&amp;=&amp;\frac{u^{T}u}{n-k}=\frac{(M_{X}y)^{T}M_{X}y}{n-k}\\
&amp;=&amp;\frac{y^{T}M_{X}y}{n-k}
\end{eqnarray*}\]

<p>and we obtain the test statistic</p>

\[\begin{eqnarray}
\nonumber
t_{\beta_{2}}&amp;=&amp;\frac{X_{2}^{T}M_{1}y}{s\left(X_{2}^{T}M_{1}X_{2}\right)^{1/2}}\\
\nonumber
&amp;=&amp;\frac{X_{2}^{T}M_{1}y}{\frac{s}{\sigma}\sigma\left(X_{2}^{T}M_{1}X_{2}\right)^{1/2}}\\
\nonumber
&amp;=&amp;\frac{z_{\beta_{2}}}{s/\sigma}\\
\label{eq9}
&amp;=&amp;\frac{z_{\beta_{2}}}{\sqrt{\frac{y^{T}M_{X}y}{\sigma^{2}}/n-k}}
\end{eqnarray}\]

<p>Then we need to show that
\(\frac{y^{T}M_{X}y}{\sigma^{2}}\sim \chi^{2}(n-k)\). If so,
(\ref{eq9}) is \(t\)
distribution with degree of freedom \((n-k)\).</p>

\[\begin{eqnarray}
\label{eq10}
\frac{y^{T}M_{X}y}{\sigma^{2}}&amp;=&amp;\frac{u^{T}M_{X}u}{\sigma^{2}}=\varepsilon^{T}M_{X}\varepsilon
\end{eqnarray}\]

<p>where
\(\varepsilon\equiv u/\sigma\sim N(0, 1)\). The second
part of Theorem 1 tells us that rightmost expression in the
(\ref{eq10}) is
distributed as \(\chi^{2}(n-k)\)</p>

<h1 id="tests-of-several-restrictions">Tests of Several Restrictions</h1>

<p>Suppose that there are \(r\) restrictions, with \(r\leq k\).</p>

\[\begin{eqnarray}
\label{eq11}
H_{0}&amp;:&amp; y=X_{1}\beta_{1}+u\\
\label{eq12}
H_{1}&amp;:&amp; y=X_{1}\beta_{1}+X_{2}\beta_{2}+u
\end{eqnarray}\]

<p>where \(X_{1}\) is an \(n\times k_{1}\) matrix,
\(X_{2}\) is an \(n\times k_{2}\) matrix, \(\beta_{1}\) is a
\(k_{1}\)-vector, \(\beta_{2}\) is a \(k_{2}\)-vector, \(k=k_{1}+k_{2}\),
and the number of restrictions \(r=k_{2}\).</p>

<p>The test statistic is</p>

\[\begin{eqnarray}
\label{eq13}
F_{\beta_{2}}&amp;\equiv&amp;\frac{(RSSR-USSR)/r}{USSR/(n-k)}
\end{eqnarray}\]

<p>Under the null hypothesis, this test statistic follow
the \(F\) distribution with \(r\) and \(n-k\) degrees of freedom.</p>

<p>It is easy to find that</p>

\[\begin{eqnarray*}
RSSR&amp;=&amp;(M_{1}y)^{T}M_{1}y=y^{T}M_{1}y\\
USSR&amp;=&amp;(M_{X}y)^{T}M_{X}y=y^{T}M_{X}y
\end{eqnarray*}\]

<p>By FWL theorem, the \(USSR\) is the SSR from the FWL regression</p>

\[\begin{eqnarray}
\label{eq14}
M_{1}y&amp;=&amp;M_{1}X_{2}\beta_{2}+M_{1}u
\end{eqnarray}\]

<p>and the \(USSR\) becomes</p>

\[\begin{eqnarray}
\nonumber
USSR&amp;=&amp;TSS-ESS\\\nonumber
&amp;=&amp;(M_{1}y)^{T}M_{1}y\\\nonumber
&amp;-&amp;[M_{1}X_{2}((M_{1}X_{2})^{T}M_{1}X_{2})^{-1}(M_{1}X_{2})^{T}M_{1}y]^{T}M_{1}X_{2}((M_{1}X_{2})^{T}M_{1}X_{2})^{-1}(M_{1}X_{2})^{T}M_{1}y\\\nonumber
&amp;=&amp;y^{T}M_{1}y-[M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}y]^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}y\\\nonumber
&amp;=&amp;y^{T}M_{1}y-y^{T}M_{1}^{T}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}y\\\nonumber
&amp;=&amp;y^{T}M_{1}y-y^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}y\\
\label{eq15}
&amp;=&amp;y^{T}M_{1}y-y^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}y
\end{eqnarray}\]

<p>Therefore,</p>

\[\begin{eqnarray*}
RSSR-USSR&amp;=&amp;y^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}y
\end{eqnarray*}\]

<p>Now the \(F\) statistics (\ref{eq14}) can be written as</p>

\[\begin{eqnarray}
\label{eq16}
F_{\beta_{2}}&amp;=&amp;\frac{y^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}y/r}{y^{T}M_{X}y/(n-k)}
\end{eqnarray}\]

<p>Under the null hypothesis \(y=X_{1}\beta_{1}+u\)</p>

\[\begin{eqnarray*}
M_{X}y&amp;=&amp;M_{X}u\\
M_{1}y&amp;=&amp;M_{1}u\\
\end{eqnarray*}\]

<p>Thus, under this hypothesis, the \(F\) statistics
(\ref{eq16}) becomes to</p>

\[\begin{eqnarray}
\nonumber
F_{\beta_{2}}&amp;=&amp;\frac{u^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}u/r}{u^{T}M_{X}u/(n-k)}\\
\label{eq17}
&amp;=&amp;\frac{\varepsilon^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}\varepsilon/r}{\varepsilon^{T}M_{X}\varepsilon/(n-k)}
\end{eqnarray}\]

<p>where \(\varepsilon=u/\sigma\)</p>

<p>The denominator of (\ref{eq17}) is distributed as \(\chi^{2}(n-k)\). The quadratic form
of numerator can be written as
\(\varepsilon^{T}P_{M_{1}X_{2}}\varepsilon\), it
is distributed as \(\chi^{2}(r)\).</p>

<h2 id="chow-test">Chow Test</h2>

<p>It is natural to divide a sample into two subsamples, e.g. larger/small
firms, men/women. We want to test whether a linear regression model has
the same coefficients for both the subsamples. Chow test can solve this
problem.</p>

<p>Suppose there are two subsamples, of lengths \(n_{1}\) and \(n_{2}\), with
\(n=n_{1}+n_{2}\). Both \(n_{1}\) and \(n_{2}\) are greater than \(k\), the
number of regressors.</p>

\[\begin{eqnarray*}
y=\left[\begin{array}{c}
y_{1}\\
y_{2}
\end{array}\right]
&amp;\mbox{and}&amp;
X=\left[\begin{array}{c}
X_{1}\\
X_{2}
\end{array}\right]
\end{eqnarray*}\]

<p>Even we need different parameter vectors \(\beta_{1}\) and
\(\beta_{2}\) for two subsamples, we can nonetheless put the subsamples
together into a regression model</p>

\[\begin{eqnarray}
\label{eq25}
\left[\begin{array}{c}
y_{1}\\
y_{2}
\end{array}\right]=
\left[\begin{array}{c}
X_{1}\\
X_{2}
\end{array}\right]\beta_{1}+
\left[\begin{array}{c}
0\\
X_{2}
\end{array}\right]\gamma+u
&amp;,&amp;u\sim N(0,\sigma^{2}I)
\end{eqnarray}\]

<p>where \(\beta_{1}+\gamma=\beta_{2}\).</p>

<p>We could rewrite (\ref{eq25})</p>

\[\begin{eqnarray}
\label{eq26}
y=X\beta_{1}+Z\gamma+u&amp;,&amp;u\sim N(0,\sigma^{2}I)
\end{eqnarray}\]

<p>The null hypothesis is \(H_{0}:\gamma=0\) and it
has been expressed as a set of \(k\) zero restrictions. We can use classic
\(F\) test. However, if \(SSR_{1}\) and \(SSR_{2}\) denote the sums of squared
residuals from two regressions, and \(RSSR\) denotes the sum of squared
residuals from regressing \(y\) on \(X\), the \(F\) statistic becomes</p>

\[\begin{eqnarray}
\label{eq27}
F_{\gamma}&amp;=&amp;\frac{(RSSR-SSR_{1}-SSR_{2})/k}{(SSR_{1}+SSR_{2})/(n-2k)}
\end{eqnarray}\]

<h1 id="large-sample-tests-in-linear-regression-models">Large-Sample Tests in Linear Regression Models</h1>

<p>Asymptotic theory is concerned with the distributions of estimators and
test statistics as the sample size \(n\) tends to infinity.</p>

<h2 id="laws-of-large-number">Laws of Large Number</h2>

<p>A law of large numbers may apply to any quantity which can be written as
an average of \(n\) random variable, that is, \(1/n\) times their sum.</p>

\[\begin{eqnarray*}
\bar{x}&amp;\equiv&amp;\frac{1}{n}\sum_{t=1}^{n}x_{t}
\end{eqnarray*}\]

<p>where \(x_{t}\) are <strong>independent</strong> random variables, each
with <strong>bounded finite variance</strong> \(\sigma_{t}^{2}\) and <strong>with a common
mean</strong> \(\mu\). As \(n\to \infty\), \(\bar{x}\to\mu\).</p>

<p>There are many different LLNs, some of which do not require that the
individual random variables have a common mean or be independent,
although the amount of dependence must be limited.</p>

<p>If we can apply a LLN to any random average, we can treat it as a
nonrandom quantity for the purpose of asymptotic analysis.</p>

<h2 id="central-limit-theorems">Central Limit Theorems</h2>

<p>In many circumstance, \(1/\sqrt{n}\) times the sum of \(n\) centered random
variables will approximately follow a normal distribution.</p>

<p>Suppose that the random variables \(x_{t}\), \(t=1,\dots,n\) are
independently and identically distributed with mean \(\mu\) and variance
\(\sigma^{2}\). Then according to the Lindebery-Lévy central limit theorem</p>

\[\begin{eqnarray*}
z&amp;\equiv&amp;\frac{1}{\sqrt{n}}\sum_{t=1}^{n}\frac{x_{t}-\mu}{\sigma}
\end{eqnarray*}\]

<p>is <strong>asymptotically distributed</strong> as \(N(0,1)\). This
means that as \(n\to\infty\), the random variable \(z\) tends to a random
variable which follows the \(N(0,1)\).</p>

<p>For a sequence of random variables, \(x_{t}\), \(t=1,\dots,n\) with
\(E(x_{t})=0\)</p>

\[\begin{eqnarray*}
\mathop{plim}_{n\to\infty}n^{-1/2}\sum_{t=1}^{n}x_{t}=x_{0}\sim N\left(0,\lim_{n\to\infty} \frac{1}{n}\sum_{t=1}^{n}Var(x_{t})\right)
\end{eqnarray*}\]

<p>It can also be applied to the multivariate version of CLTs.</p>

<h2 id="asymptotic-tests">Asymptotic Tests</h2>

<p>Suppose that the DGP is</p>

\[\begin{eqnarray}
\label{eq18}
y&amp;=&amp;X\beta_{0}+u\\
\nonumber
u&amp;\sim&amp;IID(0, \sigma^{2}_{0}I)
\end{eqnarray}\]

<p>We make another assumptions</p>

\[\begin{eqnarray}
\label{eq19}
E(u_{t}|X_{t})&amp;=&amp;0\\
\nonumber
E(u_{t}^{2}|X_{t})&amp;=&amp;\sigma^{2}_{0}
\end{eqnarray}\]

<p>From the point of view of the error terms, it says that
they are <strong>innovations</strong>. From the point of view of the explanatory
variables \(X_{t}\), they are <strong>predetermined</strong> with respect to the
errors terms.</p>

<p>To be able to use asymptotic results, we assume that the DGP for the
explanatory variables is such that</p>

\[\begin{eqnarray}
\label{eq20}
\mathop{plim}_{n\to\infty}\frac{1}{n}X^{T}X&amp;=&amp;S_{X^{T}X}
\end{eqnarray}\]

<p>where \(S_{X^{T}X}\) is a finite,
deterministic, positive definite matrix.</p>

<p>We rewrite \(t_{\beta_{2}}\) as</p>

\[\begin{eqnarray}
\label{eq21}
t_{\beta_{2}}&amp;=&amp;\left(\frac{y^{T}M_{X}y}{n-k}\right)^{-1/2}\frac{n^{-1/2}X_{2}^{T}M_{1}y}{\left(n^{-1}X_{2}^{T}M_{1}X_{2}\right)^{1/2}}
\end{eqnarray}\]

<p>As \(n\to\infty\), \(s^{2}\equiv\frac{y^{T}M_{X}y}{n-k}\)
tends to \(\sigma_{0}^{2}\). So the first factor in
(\ref{eq21}) tends to
\(1/\sigma_{0}\) as \(n\to\infty\).</p>

<p>When DGP with \(\beta_{2}=0\), we have that
\(M_{1}y=M_{1}u\), and so
(\ref{eq21}) is
asymptotically equivalent to</p>

\[\begin{eqnarray}
\label{eq22}
t_{\beta_{2}}&amp;=&amp;\frac{n^{-1/2}X_{2}^{T}M_{1}u}{\sigma_{0}\left(n^{-1}X_{2}^{T}M_{1}X_{2}\right)^{1/2}}
\end{eqnarray}\]

<p>If we reinstate the assumption that the regressors are exogenous, the
conditional variance of the numerator of
(\ref{eq22}) is</p>

\[\begin{eqnarray*}
E(X_{2}^{T}M_{1}uu^{T}M_{1}X_{2}|X)&amp;=&amp;\sigma_{0}^{2}X_{2}^{T}M_{1}X_{2}
\end{eqnarray*}\]

<p>Thus (\ref{eq22}) has mean
\(0\) and variance \(1\), conditional on \(X\). They are also the
unconditional mean and variance.</p>

<p>Under the null hypothesis, with exogenous regressors,</p>

\[\begin{eqnarray}
\label{eq23}
t_{\beta_{2}}&amp;\sim&amp;N(0,1)
\end{eqnarray}\]

<h2 id="the-t-test-with-predetermined-regressors">The \(t\) Test with Predetermined Regressors</h2>

<p>To the \(k-\)vector</p>

\[\begin{eqnarray*}
v&amp;\equiv&amp;n^{-1/2}X^{T}u=n^{-1/2}\sum_{t=1}^{n}u_{t}X^{T}
\end{eqnarray*}\]

<p>We assume \(E(u_{t}|X_{t})=0\). This implies that
\(E(u_{t}X_{t}^{T})=0\), as required for the CLT, which then tells us
that</p>

\[\begin{eqnarray*}
v&amp;\sim&amp;N\left(0, \lim_{n\to\infty}\frac{1}{n}\sum_{t=1}^{n}Var(u_{t}X_{t}^{T})\right)=N\left(0, \lim_{n\to\infty}\frac{1}{n}\sum_{t=1}^{n}E(u_{t}^{2}X_{t}^{T}X_{t})\right)
\end{eqnarray*}\]

\[\begin{eqnarray*}
\lim_{n\to\infty}\frac{1}{n}\sum_{t=1}^{n}E(u_{t}^{2}X_{t}^{T}X_{t})&amp;=&amp;\lim_{n\to\infty}\sigma_{0}^{2}\frac{1}{n}\sum_{t=1}^{n}E(X_{t}^{T}X_{t})\\
&amp;=&amp;\sigma_{0}^{2}\mathop{plim}_{n\to\infty}\frac{1}{n}\sum_{t=1}^{n}X_{t}^{T}X_{t}\\
&amp;=&amp;\sigma_{0}^{2}\mathop{plim}_{n\to\infty}\frac{1}{n}X^{T}X\\
&amp;=&amp;\sigma_{0}^{2}S_{X^{T}X}
\end{eqnarray*}\]

<h2 id="asymptotic-f-tests">Asymptotic <em>F</em> Tests</h2>

<p>\(F\) statistics (\ref{eq16}) under the null hypothesis that \(\beta_{2}=0\) can
be rewritten as</p>

\[\begin{eqnarray}
\nonumber
F_{\beta_{2}}&amp;=&amp;\frac{y^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}y/r}{y^{T}M_{X}y/(n-k)}\\
\nonumber
&amp;=&amp;\frac{\varepsilon^{T}M_{1}X_{2}(X_{2}^{T}M_{1}X_{2})^{-1}X_{2}^{T}M_{1}\varepsilon/r}{\varepsilon^{T}M_{X}\varepsilon/(n-k)}\\
\label{eq24}
&amp;=&amp;\frac{n^{-1/2}\varepsilon^{T}M_{1}X_{2}(n^{-1}X_{2}^{T}M_{1}X_{2})^{-1}n^{-1/2}X_{2}^{T}M_{1}\varepsilon/r}{\varepsilon^{T}M_{X}\varepsilon/(n-k)}
\end{eqnarray}\]

<p>where \(\varepsilon=u/\sigma_{0}\).</p>

  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Lingbo  Shen. Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>
  </body>

  <!-- jQuery -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  <!-- Mansory & imagesLoaded -->
  <script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  <script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
  
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  
</html>

